{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "# Online prediction\n",
    "\n",
    "This notebook presents the online prediction of a value function by **Monte-Carlo learning** and **TD learning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Maze, Walk, TicTacToe, Nim, ConnectFour\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent, OnlinePrediction\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolicyEvaluation\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "from model import Maze, Walk, TicTacToe, Nim, ConnectFour\n",
    "from agent import Agent, OnlinePrediction\n",
    "from dp import PolicyEvaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete the ``MCLearning`` class and test it on various environments.\n",
    "* Complete the ``TDLearning`` class and test it on various environments.\n",
    "* Compare with the exact solution obtained by Dynamic Programming when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, labeled_data, unlabeled_data):\n",
    "        self.labeled_data = labeled_data\n",
    "        self.unlabeled_data = unlabeled_data\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length is defined by the labeled data\n",
    "        return len(self.labeled_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a tuple of (labeled_data, unlabeled_data)\n",
    "        unlabeled_idx = idx % len(self.unlabeled_data)\n",
    "        return self.labeled_data[idx], self.unlabeled_data[unlabeled_idx]\n",
    "\n",
    "class CustomDataLoader:\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.labeled_indexes = list(range(len(dataset.labeled_data)))\n",
    "        self.unlabeled_indexes = list(range(len(dataset.unlabeled_data)))\n",
    "        self.unlabeled_pointer = 0\n",
    "\n",
    "        if self.shuffle:\n",
    "            torch.manual_seed(0)  # For reproducibility\n",
    "            self.labeled_indexes = torch.randperm(len(self.labeled_indexes)).tolist()\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.iter_labeled = iter(self.labeled_indexes)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        for _ in range(self.batch_size):\n",
    "            try:\n",
    "                labeled_idx = next(self.iter_labeled)\n",
    "            except StopIteration:\n",
    "                raise StopIteration\n",
    "\n",
    "            unlabeled_idx = self.unlabeled_indexes[self.unlabeled_pointer]\n",
    "            self.unlabeled_pointer = (self.unlabeled_pointer + 1) % len(self.unlabeled_indexes)\n",
    "\n",
    "            data = self.dataset[labeled_idx]\n",
    "            batch.append(data)\n",
    "\n",
    "        return batch\n",
    "\n",
    "# Example usage\n",
    "labeled_data = [torch.randn(5) for _ in range(10)]  # Replace this with your labeled data\n",
    "unlabeled_data = [torch.randn(5) for _ in range(20)]  # Replace this with your unlabeled data\n",
    "dataset = CustomDataset(labeled_data, unlabeled_data)\n",
    "loader = CustomDataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    print (\"hi\")\n",
    "    for labeled, unlabeled in loader:\n",
    "        print (\"hi\")\n",
    "        print (labeled, unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Labeled Batch Shape: tensor([[ 0.1704,  1.4061,  0.6540, -0.7445,  0.8497],\n",
      "        [ 1.2216,  1.9943, -0.4317,  0.0179,  1.0350]]), Unlabeled Batch Shape: tensor([[-0.6894,  1.4095,  0.8840,  0.0268, -0.6692],\n",
      "        [ 0.2597,  0.7758,  0.3978,  0.5062, -1.4441]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[-0.7613, -1.2306,  1.3959,  0.8658,  2.0119],\n",
      "        [-0.1957, -1.1572, -0.3526,  0.4504,  0.8583]]), Unlabeled Batch Shape: tensor([[ 0.3748,  1.7466, -0.9989, -0.0055, -0.3780],\n",
      "        [-0.1546,  0.4912, -0.7754, -1.0701,  0.4034]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[ 2.3396,  0.9407, -1.4042,  0.3062,  0.3633],\n",
      "        [ 1.0997, -0.2325,  0.0442,  0.1226, -0.3461]]), Unlabeled Batch Shape: tensor([[ 1.3248, -0.6103,  0.3881,  1.2439, -0.7752],\n",
      "        [-0.1293, -0.8127, -1.1407,  0.2515,  0.2278]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[ 0.1260, -0.2679, -0.9576, -1.6293,  0.4730],\n",
      "        [-0.4570,  0.7527,  1.0770, -1.6758, -0.6801]]), Unlabeled Batch Shape: tensor([[ 0.4190, -2.0997,  0.0444,  0.1684, -0.4006],\n",
      "        [ 0.4713, -1.1705, -0.6428,  0.4750, -0.6701]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[-0.6839, -0.3079,  0.7923, -0.9677,  0.0356],\n",
      "        [ 1.2997,  0.2098, -1.5156,  0.1466,  1.3107]]), Unlabeled Batch Shape: tensor([[-0.2979,  1.5952,  0.4580,  1.5604,  0.9058],\n",
      "        [-0.8698, -0.1078, -0.7981, -0.2681,  0.9069]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[ 0.1704,  1.4061,  0.6540, -0.7445,  0.8497],\n",
      "        [ 1.2216,  1.9943, -0.4317,  0.0179,  1.0350]]), Unlabeled Batch Shape: tensor([[ 0.9083, -0.8002,  0.1161, -0.7313,  0.0266],\n",
      "        [-0.5755, -0.0980,  0.0679, -0.0417, -0.8069]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[-0.7613, -1.2306,  1.3959,  0.8658,  2.0119],\n",
      "        [-0.1957, -1.1572, -0.3526,  0.4504,  0.8583]]), Unlabeled Batch Shape: tensor([[ 0.0106, -0.4001,  1.1348, -0.9008,  0.3253],\n",
      "        [ 0.4002, -0.2188, -0.8370,  1.7107, -2.2658]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[ 2.3396,  0.9407, -1.4042,  0.3062,  0.3633],\n",
      "        [ 1.0997, -0.2325,  0.0442,  0.1226, -0.3461]]), Unlabeled Batch Shape: tensor([[-0.9896, -0.3366, -0.5367, -3.4630,  0.3103],\n",
      "        [ 0.5729,  1.8105,  0.3606,  1.5962,  0.5569]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[ 0.1260, -0.2679, -0.9576, -1.6293,  0.4730],\n",
      "        [-0.4570,  0.7527,  1.0770, -1.6758, -0.6801]]), Unlabeled Batch Shape: tensor([[ 1.0846,  0.8740,  1.5544,  0.3421, -0.2276],\n",
      "        [ 0.6083,  1.3213, -2.0395, -0.5397,  0.2655]])\n",
      "Epoch 0, Labeled Batch Shape: tensor([[-0.6839, -0.3079,  0.7923, -0.9677,  0.0356],\n",
      "        [ 1.2997,  0.2098, -1.5156,  0.1466,  1.3107]]), Unlabeled Batch Shape: tensor([[-0.0318, -2.1451, -1.1488, -1.0417, -1.7355],\n",
      "        [ 0.2072, -0.6244,  0.0146,  0.4012,  1.5801]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[ 0.1704,  1.4061,  0.6540, -0.7445,  0.8497],\n",
      "        [ 1.2216,  1.9943, -0.4317,  0.0179,  1.0350]]), Unlabeled Batch Shape: tensor([[-0.6894,  1.4095,  0.8840,  0.0268, -0.6692],\n",
      "        [ 0.2597,  0.7758,  0.3978,  0.5062, -1.4441]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[-0.7613, -1.2306,  1.3959,  0.8658,  2.0119],\n",
      "        [-0.1957, -1.1572, -0.3526,  0.4504,  0.8583]]), Unlabeled Batch Shape: tensor([[ 0.3748,  1.7466, -0.9989, -0.0055, -0.3780],\n",
      "        [-0.1546,  0.4912, -0.7754, -1.0701,  0.4034]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[ 2.3396,  0.9407, -1.4042,  0.3062,  0.3633],\n",
      "        [ 1.0997, -0.2325,  0.0442,  0.1226, -0.3461]]), Unlabeled Batch Shape: tensor([[ 1.3248, -0.6103,  0.3881,  1.2439, -0.7752],\n",
      "        [-0.1293, -0.8127, -1.1407,  0.2515,  0.2278]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[ 0.1260, -0.2679, -0.9576, -1.6293,  0.4730],\n",
      "        [-0.4570,  0.7527,  1.0770, -1.6758, -0.6801]]), Unlabeled Batch Shape: tensor([[ 0.4190, -2.0997,  0.0444,  0.1684, -0.4006],\n",
      "        [ 0.4713, -1.1705, -0.6428,  0.4750, -0.6701]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[-0.6839, -0.3079,  0.7923, -0.9677,  0.0356],\n",
      "        [ 1.2997,  0.2098, -1.5156,  0.1466,  1.3107]]), Unlabeled Batch Shape: tensor([[-0.2979,  1.5952,  0.4580,  1.5604,  0.9058],\n",
      "        [-0.8698, -0.1078, -0.7981, -0.2681,  0.9069]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[ 0.1704,  1.4061,  0.6540, -0.7445,  0.8497],\n",
      "        [ 1.2216,  1.9943, -0.4317,  0.0179,  1.0350]]), Unlabeled Batch Shape: tensor([[ 0.9083, -0.8002,  0.1161, -0.7313,  0.0266],\n",
      "        [-0.5755, -0.0980,  0.0679, -0.0417, -0.8069]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[-0.7613, -1.2306,  1.3959,  0.8658,  2.0119],\n",
      "        [-0.1957, -1.1572, -0.3526,  0.4504,  0.8583]]), Unlabeled Batch Shape: tensor([[ 0.0106, -0.4001,  1.1348, -0.9008,  0.3253],\n",
      "        [ 0.4002, -0.2188, -0.8370,  1.7107, -2.2658]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[ 2.3396,  0.9407, -1.4042,  0.3062,  0.3633],\n",
      "        [ 1.0997, -0.2325,  0.0442,  0.1226, -0.3461]]), Unlabeled Batch Shape: tensor([[-0.9896, -0.3366, -0.5367, -3.4630,  0.3103],\n",
      "        [ 0.5729,  1.8105,  0.3606,  1.5962,  0.5569]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[ 0.1260, -0.2679, -0.9576, -1.6293,  0.4730],\n",
      "        [-0.4570,  0.7527,  1.0770, -1.6758, -0.6801]]), Unlabeled Batch Shape: tensor([[ 1.0846,  0.8740,  1.5544,  0.3421, -0.2276],\n",
      "        [ 0.6083,  1.3213, -2.0395, -0.5397,  0.2655]])\n",
      "Epoch 1, Labeled Batch Shape: tensor([[-0.6839, -0.3079,  0.7923, -0.9677,  0.0356],\n",
      "        [ 1.2997,  0.2098, -1.5156,  0.1466,  1.3107]]), Unlabeled Batch Shape: tensor([[-0.0318, -2.1451, -1.1488, -1.0417, -1.7355],\n",
      "        [ 0.2072, -0.6244,  0.0146,  0.4012,  1.5801]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[ 0.1704,  1.4061,  0.6540, -0.7445,  0.8497],\n",
      "        [ 1.2216,  1.9943, -0.4317,  0.0179,  1.0350]]), Unlabeled Batch Shape: tensor([[-0.6894,  1.4095,  0.8840,  0.0268, -0.6692],\n",
      "        [ 0.2597,  0.7758,  0.3978,  0.5062, -1.4441]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[-0.7613, -1.2306,  1.3959,  0.8658,  2.0119],\n",
      "        [-0.1957, -1.1572, -0.3526,  0.4504,  0.8583]]), Unlabeled Batch Shape: tensor([[ 0.3748,  1.7466, -0.9989, -0.0055, -0.3780],\n",
      "        [-0.1546,  0.4912, -0.7754, -1.0701,  0.4034]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[ 2.3396,  0.9407, -1.4042,  0.3062,  0.3633],\n",
      "        [ 1.0997, -0.2325,  0.0442,  0.1226, -0.3461]]), Unlabeled Batch Shape: tensor([[ 1.3248, -0.6103,  0.3881,  1.2439, -0.7752],\n",
      "        [-0.1293, -0.8127, -1.1407,  0.2515,  0.2278]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[ 0.1260, -0.2679, -0.9576, -1.6293,  0.4730],\n",
      "        [-0.4570,  0.7527,  1.0770, -1.6758, -0.6801]]), Unlabeled Batch Shape: tensor([[ 0.4190, -2.0997,  0.0444,  0.1684, -0.4006],\n",
      "        [ 0.4713, -1.1705, -0.6428,  0.4750, -0.6701]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[-0.6839, -0.3079,  0.7923, -0.9677,  0.0356],\n",
      "        [ 1.2997,  0.2098, -1.5156,  0.1466,  1.3107]]), Unlabeled Batch Shape: tensor([[-0.2979,  1.5952,  0.4580,  1.5604,  0.9058],\n",
      "        [-0.8698, -0.1078, -0.7981, -0.2681,  0.9069]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[ 0.1704,  1.4061,  0.6540, -0.7445,  0.8497],\n",
      "        [ 1.2216,  1.9943, -0.4317,  0.0179,  1.0350]]), Unlabeled Batch Shape: tensor([[ 0.9083, -0.8002,  0.1161, -0.7313,  0.0266],\n",
      "        [-0.5755, -0.0980,  0.0679, -0.0417, -0.8069]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[-0.7613, -1.2306,  1.3959,  0.8658,  2.0119],\n",
      "        [-0.1957, -1.1572, -0.3526,  0.4504,  0.8583]]), Unlabeled Batch Shape: tensor([[ 0.0106, -0.4001,  1.1348, -0.9008,  0.3253],\n",
      "        [ 0.4002, -0.2188, -0.8370,  1.7107, -2.2658]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[ 2.3396,  0.9407, -1.4042,  0.3062,  0.3633],\n",
      "        [ 1.0997, -0.2325,  0.0442,  0.1226, -0.3461]]), Unlabeled Batch Shape: tensor([[-0.9896, -0.3366, -0.5367, -3.4630,  0.3103],\n",
      "        [ 0.5729,  1.8105,  0.3606,  1.5962,  0.5569]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[ 0.1260, -0.2679, -0.9576, -1.6293,  0.4730],\n",
      "        [-0.4570,  0.7527,  1.0770, -1.6758, -0.6801]]), Unlabeled Batch Shape: tensor([[ 1.0846,  0.8740,  1.5544,  0.3421, -0.2276],\n",
      "        [ 0.6083,  1.3213, -2.0395, -0.5397,  0.2655]])\n",
      "Epoch 2, Labeled Batch Shape: tensor([[-0.6839, -0.3079,  0.7923, -0.9677,  0.0356],\n",
      "        [ 1.2997,  0.2098, -1.5156,  0.1466,  1.3107]]), Unlabeled Batch Shape: tensor([[-0.0318, -2.1451, -1.1488, -1.0417, -1.7355],\n",
      "        [ 0.2072, -0.6244,  0.0146,  0.4012,  1.5801]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, labeled_data, unlabeled_data):\n",
    "        self.labeled_data = labeled_data\n",
    "        self.unlabeled_data = unlabeled_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.labeled_data), len(self.unlabeled_data))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labeled_idx = idx % len(self.labeled_data) if self.labeled_data else None\n",
    "        unlabeled_idx = idx % len(self.unlabeled_data) if self.unlabeled_data else None\n",
    "\n",
    "        labeled_sample = self.labeled_data[labeled_idx] if labeled_idx is not None else None\n",
    "        unlabeled_sample = self.unlabeled_data[unlabeled_idx] if unlabeled_idx is not None else None\n",
    "\n",
    "        return labeled_sample, unlabeled_sample\n",
    "\n",
    "# Example usage\n",
    "labeled_data = [torch.randn(5) for _ in range(10)]  # Replace this with your labeled data\n",
    "unlabeled_data = [torch.randn(5) for _ in range(20)]  # Replace this with your unlabeled data\n",
    "\n",
    "custom_dataset = CustomDataset(labeled_data, unlabeled_data)\n",
    "custom_loader = DataLoader(custom_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3):  # Replace 3 with the number of epochs you want\n",
    "    for labeled_batch, unlabeled_batch in custom_loader:\n",
    "        # Your training logic here\n",
    "        print(\"Epoch {}, Labeled Batch Shape: {}, Unlabeled Batch Shape: {}\".format(\n",
    "            epoch, labeled_batch if labeled_batch is not None else None,\n",
    "            unlabeled_batch if unlabeled_batch is not None else None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.6894,  1.4095,  0.8840,  0.0268, -0.6692]),\n",
       " tensor([ 0.2597,  0.7758,  0.3978,  0.5062, -1.4441]),\n",
       " tensor([ 0.3748,  1.7466, -0.9989, -0.0055, -0.3780]),\n",
       " tensor([-0.1546,  0.4912, -0.7754, -1.0701,  0.4034]),\n",
       " tensor([ 1.3248, -0.6103,  0.3881,  1.2439, -0.7752]),\n",
       " tensor([-0.1293, -0.8127, -1.1407,  0.2515,  0.2278]),\n",
       " tensor([ 0.4190, -2.0997,  0.0444,  0.1684, -0.4006]),\n",
       " tensor([ 0.4713, -1.1705, -0.6428,  0.4750, -0.6701]),\n",
       " tensor([-0.2979,  1.5952,  0.4580,  1.5604,  0.9058]),\n",
       " tensor([-0.8698, -0.1078, -0.7981, -0.2681,  0.9069]),\n",
       " tensor([ 0.9083, -0.8002,  0.1161, -0.7313,  0.0266]),\n",
       " tensor([-0.5755, -0.0980,  0.0679, -0.0417, -0.8069]),\n",
       " tensor([ 0.0106, -0.4001,  1.1348, -0.9008,  0.3253]),\n",
       " tensor([ 0.4002, -0.2188, -0.8370,  1.7107, -2.2658]),\n",
       " tensor([-0.9896, -0.3366, -0.5367, -3.4630,  0.3103]),\n",
       " tensor([0.5729, 1.8105, 0.3606, 1.5962, 0.5569]),\n",
       " tensor([ 1.0846,  0.8740,  1.5544,  0.3421, -0.2276]),\n",
       " tensor([ 0.6083,  1.3213, -2.0395, -0.5397,  0.2655]),\n",
       " tensor([-0.0318, -2.1451, -1.1488, -1.0417, -1.7355]),\n",
       " tensor([ 0.2072, -0.6244,  0.0146,  0.4012,  1.5801])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCLearning(OnlinePrediction):\n",
    "    \"\"\"Online prediction by Monte-Carlo.\"\"\"\n",
    "        \n",
    "    def update_values(self):\n",
    "        \"\"\"Update the values from an episode.\"\"\"\n",
    "        stop, states, rewards = self.get_episode()\n",
    "        gain = 0\n",
    "        # backward update\n",
    "        for state, reward in zip(reversed(states), reversed(rewards)):\n",
    "            self.add_state(state)\n",
    "            state_code = self.model.encode(state)\n",
    "            # number of visits to this state\n",
    "            self.state_count[state_code] += 1\n",
    "            # value of this state\n",
    "            # to be modified\n",
    "            # begin\n",
    "            gain = 0\n",
    "            # end \n",
    "            diff = gain - self.state_value[state_code]\n",
    "            count = self.state_count[state_code]\n",
    "            self.state_value[state_code] += diff / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDLearning(OnlinePrediction):\n",
    "    \"\"\"Online prediction by TD learning.\"\"\"\n",
    "        \n",
    "    def update_values(self):\n",
    "        \"\"\"Update values online.\"\"\"\n",
    "        self.model.__init__()\n",
    "        for t in range(self.n_steps):\n",
    "            state = self.model.state\n",
    "            self.add_state(state)\n",
    "            state_code = self.model.encode(state)\n",
    "            # number of visits to this state\n",
    "            self.state_count[state_code] += 1\n",
    "            \n",
    "            # next state            \n",
    "            action = self.get_action(state)\n",
    "            reward, stop = self.model.step(action)\n",
    "            next_state = self.model.state\n",
    "            self.add_state(next_state)\n",
    "            next_state_code = self.model.encode(next_state)\n",
    "            \n",
    "            # to be modified\n",
    "            # begin\n",
    "            self.state_value[state_code] += 0\n",
    "            # end\n",
    "            \n",
    "            if stop:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = MCLearning(model, policy='random', gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 100\n",
    "for t in range(n_episodes):\n",
    "    algo.update_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = algo.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.display_values(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = algo.improve_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.display_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Maze()\n",
    "# set parameters\n",
    "maze_map = np.load('maze_small.npy')\n",
    "model.set_parameters(maze_map, (1, 0), [(3, 8)])\n",
    "# init\n",
    "model = Maze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo = MCLearning(model, policy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1000\n",
    "for t in range(n_episodes):\n",
    "    algo.update_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = algo.get_values()\n",
    "model.display_values(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = algo.improve_policy()\n",
    "model.display_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Game = TicTacToe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random player\n",
    "game = Game()\n",
    "agent = Agent(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(agent.get_gains(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# online prediction of the random player\n",
    "algo = MCLearning(game, policy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might adapt the number of games\n",
    "n_games = 100\n",
    "for t in range(n_games):\n",
    "    algo.update_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy improvement\n",
    "policy = algo.improve_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test this new policy\n",
    "agent = Agent(game, policy)\n",
    "np.unique(agent.get_gains(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a better adversary\n",
    "game = TicTacToe(adversary_policy='one_step')\n",
    "agent = Agent(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(agent.get_gains(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# online prediction against this adversary\n",
    "algo = MCLearning(game, policy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and improve your player!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# online prediction of a better player\n",
    "algo = MCLearning(game, policy='one_step')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
